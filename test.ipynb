{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70348905-ce6d-4166-b8b9-82e39835e13f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (921701632.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mSSIM AND PSNR OF THE ORIGINAL AND THE WATERMARKED FRAME/AND SSIM AND THE MSE OF THE GENERATED GAN WATERMARK AND THE EXTRACTED WATERMARK WITHOUT ANY DEEPFAKE\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "SSIM AND PSNR OF THE ORIGINAL AND THE WATERMARKED FRAME/AND SSIM AND THE MSE OF THE GENERATED GAN WATERMARK AND THE EXTRACTED WATERMARK WITHOUT ANY DEEPFAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b08237-9fb9-4690-ace2-d3deea710438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.0\n",
      "    Uninstalling numpy-2.0.0:\n",
      "      Successfully uninstalled numpy-2.0.0\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyresparser 1.0.6 requires spacy>=2.1.4, which is not installed.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916496ee-29aa-4f2e-a696-fe99730a0968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_5220\\2758993646.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py\", line 45, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 46, in <module>\n",
      "    from tensorflow.python import pywrap_tfe\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py\", line 25, in <module>\n",
      "    from tensorflow.python._pywrap_tfe import *\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[32m     43\u001b[39m     sys.stderr.write(msg + tb_msg)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     46\u001b[39m ret = \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_5220\\2758993646.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py\", line 45, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 49, in <module>\n",
      "    from tensorflow.python.client import pywrap_tf_session\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\client\\pywrap_tf_session.py\", line 19, in <module>\n",
      "    from tensorflow.python.client._pywrap_tf_session import *\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[32m     43\u001b[39m     sys.stderr.write(msg + tb_msg)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     46\u001b[39m ret = \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_5220\\2758993646.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py\", line 45, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 50, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 37, in <module>\n",
      "    from tensorflow.python.eager import execute\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 21, in <module>\n",
      "    from tensorflow.python.framework import dtypes\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\", line 21, in <module>\n",
      "    import ml_dtypes\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ml_dtypes\\__init__.py\", line 32, in <module>\n",
      "    from ml_dtypes._finfo import finfo\n",
      "  File \"C:\\Users\\venka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ml_dtypes\\_finfo.py\", line 19, in <module>\n",
      "    from ml_dtypes._ml_dtypes_ext import bfloat16\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[32m     43\u001b[39m     sys.stderr.write(msg + tb_msg)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     46\u001b[39m ret = \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[31mImportError\u001b[39m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mskimage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m peak_signal_noise_ratio \u001b[38;5;28;01mas\u001b[39;00m psnr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:45\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     43\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mag_ctx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01minspect\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mthreading\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[32m     25\u001b[39m stacks = threading.local()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext_managers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mcontextlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:50\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m monitoring\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:37\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cancellation\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m executor\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m monitoring\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_conversion_registry\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mdataclasses\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Type, Sequence, Optional\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mml_dtypes\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ml_dtypes\\__init__.py:32\u001b[39m\n\u001b[32m     16\u001b[39m __all__ = [\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m__version__\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbfloat16\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m'\u001b[39m\u001b[33muint4\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     28\u001b[39m ]\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Type\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_finfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m finfo\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_iinfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iinfo\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bfloat16\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ml_dtypes\\_finfo.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Overload of numpy.finfo to handle dtypes defined in ml_dtypes.\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bfloat16\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m float8_e4m3b11fnuz\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m float8_e4m3fn\n",
      "\u001b[31mImportError\u001b[39m: numpy.core.umath failed to import"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def build_generator():\n",
    "    \"\"\" Define a simple CNN generator for watermark prediction \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=(128, 128, 1))\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    model = tf.keras.Model(inputs, x, name=\"Generator\")\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "weights_path = \"./model_weights/generator_epoch_4900.weights.h5\"\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    generator.load_weights(weights_path)\n",
    "    print(\" Generator weights loaded successfully!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\" Weights file not found at {weights_path}\")\n",
    "\n",
    "INPUT_VIDEO_PATH = \"./input2.mp4\"\n",
    "OUTPUT_VIDEO_PATH = \"./output_watermarked2.mp4\"\n",
    "GENERATED_WATERMARK_PATH = \"./generated_watermarks2\"\n",
    "EXTRACTED_WATERMARK_PATH = \"./extracted_watermarks2\"\n",
    "\n",
    "os.makedirs(GENERATED_WATERMARK_PATH, exist_ok=True)\n",
    "os.makedirs(EXTRACTED_WATERMARK_PATH, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(INPUT_VIDEO_PATH)\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "frame_count = 0\n",
    "psnr_values = []\n",
    "ssim_values = []\n",
    "watermark_ssim_values = []\n",
    "watermark_mse_values = []\n",
    "\n",
    "alpha = 0.03\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  \n",
    "\n",
    "    frame = frame.astype(np.float32) / 255.0  \n",
    "    \n",
    "    gray_frame = cv2.cvtColor((frame * 255).astype(np.uint8), cv2.COLOR_BGR2GRAY)\n",
    "    resized_frame = cv2.resize(gray_frame, (128, 128)) / 255.0  \n",
    "    input_frame = np.expand_dims(resized_frame, axis=[0, -1])\n",
    "    watermark = generator.predict(input_frame)[0, :, :, 0]  \n",
    "                                                                    \n",
    "    watermark_resized = cv2.resize(watermark, (frame_width, frame_height))\n",
    "\n",
    "    generated_watermark_path = os.path.join(GENERATED_WATERMARK_PATH, f\"frame_{frame_count:04d}.png\")\n",
    "    cv2.imwrite(generated_watermark_path, (watermark_resized * 255).astype(np.uint8))\n",
    "\n",
    "    watermarked_frame = frame + alpha * np.expand_dims(watermark_resized, axis=-1)\n",
    "    watermarked_frame = np.clip(watermarked_frame * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "    out.write(watermarked_frame)\n",
    "\n",
    "    original_frame = (frame * 255).astype(np.uint8)\n",
    "    psnr_value = psnr(original_frame, watermarked_frame, data_range=255)\n",
    "    ssim_value = ssim(original_frame, watermarked_frame, data_range=255, win_size=3, channel_axis=-1)\n",
    "\n",
    "    psnr_values.append(psnr_value)\n",
    "    ssim_values.append(ssim_value)\n",
    "\n",
    "    extracted_watermark = (watermarked_frame.astype(np.float32) - frame * 255) / alpha\n",
    "    extracted_watermark = np.mean(extracted_watermark, axis=-1) \n",
    "\n",
    "    extracted_watermark = cv2.GaussianBlur(extracted_watermark, (3, 3), 0)\n",
    "\n",
    "    extracted_watermark = np.clip(extracted_watermark, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    extracted_watermark_path = os.path.join(EXTRACTED_WATERMARK_PATH, f\"frame_{frame_count:04d}.png\")\n",
    "    cv2.imwrite(extracted_watermark_path, extracted_watermark)\n",
    "\n",
    "    h, w = watermark_resized.shape\n",
    "    h_start, h_end = h // 4, 3 * h // 4\n",
    "    w_start, w_end = w // 4, 3 * w // 4\n",
    "    cropped_original = watermark_resized[h_start:h_end, w_start:w_end]\n",
    "    cropped_extracted = extracted_watermark[h_start:h_end, w_start:w_end]\n",
    "\n",
    "    watermark_ssim = ssim(cropped_original, cropped_extracted.astype(np.float32) / 255, data_range=1.0)\n",
    "    watermark_mse = mean_squared_error(cropped_original.flatten(), cropped_extracted.flatten() / 255)\n",
    "\n",
    "    watermark_ssim_values.append(watermark_ssim)\n",
    "    watermark_mse_values.append(watermark_mse)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "avg_psnr = np.mean(psnr_values)\n",
    "avg_ssim = np.mean(ssim_values)\n",
    "avg_watermark_ssim = np.mean(watermark_ssim_values)\n",
    "avg_watermark_mse = np.mean(watermark_mse_values)\n",
    "\n",
    "print(f\" Watermarked video saved: {OUTPUT_VIDEO_PATH}\")\n",
    "print(f\" Generated watermarks saved in: {GENERATED_WATERMARK_PATH}\")\n",
    "print(f\" Extracted watermarks saved in: {EXTRACTED_WATERMARK_PATH}\")\n",
    "print(f\"  PSNR: {avg_psnr:.4f} (More Than 30 is better)\")\n",
    "print(f\"  SSIM : {avg_ssim:.6f} (Closer to 1 is better)\")\n",
    "print(f\" Watermark SSIM: {avg_watermark_ssim:.4f} (Closer to 1 is better)\")\n",
    "print(f\" Watermark MSE: {avg_watermark_mse:.6f} (Lower is better)\")\n",
    "print(f\" Model Accuracy (Based on SSIM): {avg_watermark_ssim * 100:.2f}%\")\n",
    "print(f\"Number of Frames:{frame_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879a91d-9601-477b-9a0d-a469b27f2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT THE WATERMARK FROM THE DEEPFAKED WATERMARK VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc766916-234d-4170-9a8a-afe94f07c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "ORIGINAL_VIDEO_PATH = \"./input2.mp4\"\n",
    "WATERMARKED_VIDEO_PATH = \"./deepfaked2.mp4\"\n",
    "EXTRACTED_WATERMARK_PATH = \"./deepfaked_extracted_watermarks2\"\n",
    "\n",
    "os.makedirs(EXTRACTED_WATERMARK_PATH, exist_ok=True)\n",
    "\n",
    "cap_original = cv2.VideoCapture(ORIGINAL_VIDEO_PATH)\n",
    "cap_watermarked = cv2.VideoCapture(WATERMARKED_VIDEO_PATH)\n",
    "\n",
    "alpha = 0.03\n",
    "\n",
    "frame_count = 0\n",
    "ssim_values = []\n",
    "\n",
    "while cap_original.isOpened() and cap_watermarked.isOpened():\n",
    "    ret_orig, frame_orig = cap_original.read()\n",
    "    ret_watermarked, frame_watermarked = cap_watermarked.read()\n",
    "\n",
    "    if not ret_orig or not ret_watermarked:\n",
    "        break \n",
    "\n",
    "    frame_orig = frame_orig.astype(np.float32)\n",
    "    frame_watermarked = frame_watermarked.astype(np.float32)\n",
    "\n",
    "    extracted_watermark = (frame_watermarked - frame_orig) / alpha\n",
    "\n",
    "    extracted_watermark = np.mean(extracted_watermark, axis=-1)\n",
    "\n",
    "    extracted_watermark = cv2.GaussianBlur(extracted_watermark, (3, 3), 0)\n",
    "\n",
    "    extracted_watermark = np.clip(extracted_watermark, 0, 255).astype(np.uint8)\n",
    "\n",
    "    extracted_watermark_path = os.path.join(EXTRACTED_WATERMARK_PATH, f\"frame_{frame_count:04d}.png\")\n",
    "    cv2.imwrite(extracted_watermark_path, extracted_watermark)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap_original.release()\n",
    "cap_watermarked.release()\n",
    "\n",
    "print(f\" Extracted watermarks saved in: {EXTRACTED_WATERMARK_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb341dfc-7f08-4eda-8fad-de7822d01d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculating the SSIM of the GAN Generated Watermark and the extracted watermark from deepfaked video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7552a2a-ddb8-4ea2-8c7e-bc2e7dacde5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "GENERATED_WATERMARK_PATH = \"./generated_watermarks2\"\n",
    "EXTRACTED_WATERMARK_PATH = \"./deepfaked_extracted_watermarks2\"\n",
    "\n",
    "generated_files = sorted(os.listdir(GENERATED_WATERMARK_PATH))\n",
    "extracted_files = sorted(os.listdir(EXTRACTED_WATERMARK_PATH))\n",
    "\n",
    "assert len(generated_files) == len(extracted_files), \"Mismatch in number of frames!\"\n",
    "\n",
    "SSIM_THRESHOLD = 0.7\n",
    "MSE_THRESHOLD = 0.02 \n",
    "\n",
    "deepfake_frames = 0\n",
    "total_frames = len(generated_files)\n",
    "ssim_values = []\n",
    "mse_values = []\n",
    "\n",
    "for gen_file, ext_file in zip(generated_files, extracted_files):\n",
    "    gen_path = os.path.join(GENERATED_WATERMARK_PATH, gen_file)\n",
    "    ext_path = os.path.join(EXTRACTED_WATERMARK_PATH, ext_file)\n",
    "\n",
    "    gen_img = cv2.imread(gen_path, cv2.IMREAD_GRAYSCALE) / 255.0  \n",
    "    ext_img = cv2.imread(ext_path, cv2.IMREAD_GRAYSCALE) / 255.0  \n",
    "\n",
    "    ssim_value = ssim(gen_img, ext_img, data_range=1.0)\n",
    "    mse_value = mean_squared_error(gen_img.flatten(), ext_img.flatten())\n",
    "\n",
    "    ssim_values.append(ssim_value)\n",
    "    mse_values.append(mse_value)\n",
    "\n",
    "    if ssim_value < SSIM_THRESHOLD or mse_value > MSE_THRESHOLD:\n",
    "        deepfake_frames += 1\n",
    "\n",
    "avg_ssim = np.mean(ssim_values)\n",
    "deepfake_percentage = (deepfake_frames / total_frames) * 100\n",
    "if avg_ssim>=0.6:\n",
    "    print(\"video is authentic you are eligible for copyright\")\n",
    "else:\n",
    "    print(\" you can proceed for further steps\")\n",
    "    \n",
    "    \n",
    "\n",
    "print(f\" Average SSIM: {avg_ssim:.4f} (Closer to 1 is better)\")\n",
    "print(f\" Deepfake Suspicious Frames: {deepfake_frames}/{total_frames} ({deepfake_percentage:.2f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24f83a-7b13-4088-b3dc-629cff8f2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracting the watermark stored in the dwt/dct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789c1a1-5ac2-498a-bc8f-27b3027f9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_watermark_from_image(watermarked_img_path, alpha=0.05, watermark_shape=(50, 50)):\n",
    "    wm_img = cv2.imread(watermarked_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if wm_img is None:\n",
    "        raise ValueError(f\"Could not load image: {watermarked_img_path}\")\n",
    "    coeffs = pywt.dwt2(wm_img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    dct_LL = cv2.dct(np.float32(LL))\n",
    "    estimated_original = cv2.medianBlur(dct_LL, 5)\n",
    "    watermark_diff = (dct_LL - estimated_original) / alpha\n",
    "    watermark = cv2.resize(watermark_diff, watermark_shape)\n",
    "    watermark = cv2.normalize(watermark, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    return watermark.astype(np.uint8)\n",
    "\n",
    "def batch_extract_watermarks(input_dir, output_dir, alpha=0.05, watermark_shape=(50, 50)):\n",
    "    \"\"\"\n",
    "    Processes all images in a directory to extract watermarks\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    frame_files = sorted([f for f in os.listdir(input_dir) if f.startswith('frame_') and f.endswith('.png')])\n",
    "    watermark_accumulator = None\n",
    "    valid_count = 0\n",
    "    for frame_file in tqdm(frame_files, desc=\"Extracting watermarks\"):\n",
    "        try:\n",
    "            frame_path = os.path.join(input_dir, frame_file)\n",
    "            wm = extract_watermark_from_image(frame_path, alpha, watermark_shape)\n",
    "            if watermark_accumulator is None:\n",
    "                watermark_accumulator = np.zeros_like(wm, dtype=np.float32)\n",
    "            watermark_accumulator += wm.astype(np.float32)\n",
    "            valid_count += 1\n",
    "            output_path = os.path.join(output_dir, f\"extracted_{frame_file}\")\n",
    "            cv2.imwrite(output_path, wm)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {frame_file}: {str(e)}\")\n",
    "    if valid_count > 0:\n",
    "        avg_watermark = (watermark_accumulator / valid_count).astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(output_dir, \"averaged_watermark.png\"), avg_watermark)\n",
    "        print(f\"Successfully processed {valid_count} frames. Average watermark saved.\")\n",
    "    else:\n",
    "        print(\"No valid frames processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_DIR = \"./generated_watermarks2\"  # Folder with your watermarked frames\n",
    "    OUTPUT_DIR = \"./check_generated2\"  # Where to save extracted watermarks\n",
    "    ALPHA = 0.05  # Must match your embedding strength\n",
    "    WATERMARK_SHAPE = (50, 50)  # Must match your original watermark dimensions\n",
    "    \n",
    "    # Run extraction\n",
    "    batch_extract_watermarks(INPUT_DIR, OUTPUT_DIR, ALPHA, WATERMARK_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba9744-67b5-49dc-9a5c-ffc49c3a100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracting the watermark embeded in the deepfaked frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b15ed-fa34-4abd-be24-fa8cb59eda63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_watermark_from_image(watermarked_img_path, alpha=0.05, watermark_shape=(50, 50)):\n",
    "    wm_img = cv2.imread(watermarked_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if wm_img is None:\n",
    "        raise ValueError(f\"Could not load image: {watermarked_img_path}\")\n",
    "    coeffs = pywt.dwt2(wm_img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    dct_LL = cv2.dct(np.float32(LL))\n",
    "    estimated_original = cv2.medianBlur(dct_LL, 5)\n",
    "    watermark_diff = (dct_LL - estimated_original) / alpha\n",
    "    watermark = cv2.resize(watermark_diff, watermark_shape)\n",
    "    watermark = cv2.normalize(watermark, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    return watermark.astype(np.uint8)\n",
    "\n",
    "def batch_extract_watermarks(input_dir, output_dir, alpha=0.05, watermark_shape=(50, 50)):\n",
    "    \"\"\"\n",
    "    Processes all images in a directory to extract watermarks\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    frame_files = sorted([f for f in os.listdir(input_dir) if f.startswith('frame_') and f.endswith('.png')])\n",
    "    watermark_accumulator = None\n",
    "    valid_count = 0\n",
    "    for frame_file in tqdm(frame_files, desc=\"Extracting watermarks\"):\n",
    "        try:\n",
    "            frame_path = os.path.join(input_dir, frame_file)\n",
    "            wm = extract_watermark_from_image(frame_path, alpha, watermark_shape)\n",
    "            if watermark_accumulator is None:\n",
    "                watermark_accumulator = np.zeros_like(wm, dtype=np.float32)\n",
    "            watermark_accumulator += wm.astype(np.float32)\n",
    "            valid_count += 1\n",
    "            output_path = os.path.join(output_dir, f\"extracted_{frame_file}\")\n",
    "            cv2.imwrite(output_path, wm)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {frame_file}: {str(e)}\")\n",
    "    if valid_count > 0:\n",
    "        avg_watermark = (watermark_accumulator / valid_count).astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(output_dir, \"averaged_watermark.png\"), avg_watermark)\n",
    "        print(f\"Successfully processed {valid_count} frames. Average watermark saved.\")\n",
    "    else:\n",
    "        print(\"No valid frames processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_DIR = \"./deepfaked_extracted_watermarks2\"  # Folder with your watermarked frames\n",
    "    OUTPUT_DIR = \"./deepfaked_extracted2\"  # Where to save extracted watermarks\n",
    "    ALPHA = 0.05  # Must match your embedding strength\n",
    "    WATERMARK_SHAPE = (50, 50)  # Must match your original watermark dimensions\n",
    "    \n",
    "    # Run extraction\n",
    "    batch_extract_watermarks(INPUT_DIR, OUTPUT_DIR, ALPHA, WATERMARK_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e6e81-98d6-4347-9e71-12ad65665fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculating the SSIM for the embeded (50*50)sized watermark before and after deepfake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c13dc2-7f1e-465a-953d-2a7fd86ad896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    \"\"\"Calculate SSIM between two images\"\"\"\n",
    "    # Ensure images are the same size\n",
    "    if img1.shape != img2.shape:\n",
    "        img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "    \n",
    "    # Convert to float32 for calculation\n",
    "    img1 = img1.astype(np.float32)\n",
    "    img2 = img2.astype(np.float32)\n",
    "    \n",
    "    # Calculate SSIM (multichannel=False for grayscale)\n",
    "    return ssim(img1, img2, data_range=255, full=False)\n",
    "\n",
    "def compare_folders(generated_dir, extracted_dir):\n",
    "    \"\"\"Compare SSIM between corresponding images in two folders\"\"\"\n",
    "    # Get sorted list of files\n",
    "    gen_files = sorted([f for f in os.listdir(generated_dir) if f.endswith('.png')])\n",
    "    ext_files = sorted([f for f in os.listdir(extracted_dir) if f.endswith('.png')])\n",
    "    \n",
    "    # Verify we have matching files\n",
    "    if len(gen_files) != len(ext_files):\n",
    "        print(f\"Warning: Folder count mismatch - Generated: {len(gen_files)}, Extracted: {len(ext_files)}\")\n",
    "    \n",
    "    ssim_values = []\n",
    "    \n",
    "    for gen_file, ext_file in tqdm(zip(gen_files, ext_files), total=min(len(gen_files), len(ext_files))):\n",
    "        gen_path = os.path.join(generated_dir, gen_file)\n",
    "        ext_path = os.path.join(extracted_dir, ext_file)\n",
    "        \n",
    "        # Load images as grayscale\n",
    "        gen_img = cv2.imread(gen_path, cv2.IMREAD_GRAYSCALE)\n",
    "        ext_img = cv2.imread(ext_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if gen_img is None or ext_img is None:\n",
    "            print(f\"Skipping {gen_file} - couldn't load one or both images\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate SSIM\n",
    "        current_ssim = calculate_ssim(gen_img, ext_img)\n",
    "        ssim_values.append(current_ssim)\n",
    "        \n",
    "        print(f\"{gen_file} vs {ext_file}: SSIM = {current_ssim:.4f}\")\n",
    "    \n",
    "    if ssim_values:\n",
    "        avg_ssim = np.mean(ssim_values)\n",
    "        print(f\"\\nAverage SSIM across {len(ssim_values)} frames: {avg_ssim:.4f}\")\n",
    "        return avg_ssim\n",
    "    else:\n",
    "        print(\"No valid image pairs found\")\n",
    "        return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    GENERATED_DIR = \"./check_generated2\"    # Folder with watermarked images\n",
    "    EXTRACTED_DIR = \"./deepfaked_extracted2\"    # Folder with extracted watermarks\n",
    "    \n",
    "    # Run comparison\n",
    "    average_ssim = compare_folders(GENERATED_DIR, EXTRACTED_DIR)\n",
    "    if average_ssim>=0.7:\n",
    "        print(\"video is authentic you are eligible for copyright\")\n",
    "    else:\n",
    "        print(\"not eligible for copyright\")\n",
    "        \n",
    "    # Save results to file\n",
    "    with open(\"ssim_results.txt\", \"w\") as f:\n",
    "        f.write(f\"Average SSIM: {average_ssim:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ed6f1-6f12-4d65-a865-3a1f1b643636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
